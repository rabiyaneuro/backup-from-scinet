{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "2a2362ed-e353-48f1-b8d2-ffb62a04a43e"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "OUTPUT_PATH = '/scratch/l/lfefebvr/noorir/model/Output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1a3cae7d-dbd6-478d-adce-fef91768bc10"
    }
   },
   "source": [
    "Extra Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "2cb84aed-b22a-4757-8bd4-a213925b52a1"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ts(nodes, all_ts):\n",
    "\n",
    "\n",
    "    plt.figure(2, figsize=(40, 6))\n",
    "    for sing_node in range(nodes):\n",
    "        plt.plot(np.array(all_ts)[sing_node])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing which jobs to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB = ['1130634', '1130638']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1d213cc8-e9a9-4875-b33a-205219eaf1cd"
    }
   },
   "source": [
    "Loading all the data we need for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "452522e7-d6ca-46d8-93cc-0af9aef18548"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vars files successfully 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1130634': '/scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/load_genvars_delays_pli_corr0.py',\n",
       " '1130638': '/scratch/l/lfefebvr/noorir/model/Output/2019-04-13/1130638/load_genvars_delays_pli_corr1.py'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NTASKS =[120]\n",
    "NUM_JOBS = len(JOB)\n",
    "# Loading variable file names we will use for analysis into a dictionary\n",
    "\n",
    "load_files = {} #names of all the load_vars_ts_delays files\n",
    "\n",
    "for job in JOB:\n",
    "    var = glob.glob(OUTPUT_PATH+\"*/\"+job+\"/\"+\"load_genvars_delay*\")\n",
    "    if len(var) ==1:\n",
    "        load_files[job] = glob.glob(OUTPUT_PATH+\"*/\"+job+\"/\"+\"load_genvars_delay*\")[0]\n",
    "        \n",
    "        \n",
    "if len(load_files.keys()) == len(JOB):\n",
    "    print(\"Loaded vars files successfully\", len(JOB))\n",
    "load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 45 connections\n",
      "    using t=0.000s..0.599s for estimation (600 points)\n",
      "    frequencies: 13.3Hz..30.0Hz (11 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    using FFT with a Hanning window to estimate spectra\n",
      "    the following metrics will be computed: WPLI\n",
      "    computing connectivity for epoch 1\n",
      "    computing connectivity for epoch 2\n",
      "    computing connectivity for epoch 3\n",
      "    assembling connectivity matrix (filling the upper triangular region of the matrix)\n",
      "[Connectivity computation done]\n",
      "0   0.12917258911   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank28_nit5700.npy\n",
      "0   0.117380542302   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank0_nit5700.npy\n",
      "0   0.169147350254   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank12_nit5700.npy\n",
      "0   0.121616760786   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank66_nit5700.npy\n",
      "0   0.0845774042758   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank8_nit5700.npy\n",
      "0   0.156031561545   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank108_nit5700.npy\n",
      "0   0.100919273219   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank49_nit5700.npy\n",
      "0   0.1899668346   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank54_nit5700.npy\n",
      "0   0.112077608833   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank52_nit5700.npy\n",
      "0   0.165691432399   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank5_nit5700.npy\n",
      "0   0.124706237204   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank47_nit5700.npy\n",
      "0   0.16089608632   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank104_nit5700.npy\n",
      "0   0.0925106099813   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank39_nit5700.npy\n",
      "0   0.161006016177   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank69_nit5700.npy\n",
      "0   0.165218045172   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank2_nit5700.npy\n",
      "0   0.170451208023   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank51_nit5700.npy\n",
      "0   0.0818648807936   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank78_nit5700.npy\n",
      "0   0.125593022211   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank24_nit5700.npy\n",
      "0   0.165691432399   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank4_nit5700.npy\n",
      "0   0.117380542302   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank1_nit5700.npy\n",
      "0   0.136694056719   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank93_nit5700.npy\n",
      "0   0.1234999966   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank11_nit5700.npy\n",
      "0   0.0851313189659   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank86_nit5700.npy\n",
      "0   0.116721822034   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank106_nit5700.npy\n",
      "0   0.122689151292   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank16_nit5700.npy\n",
      "0   0.164660342883   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank92_nit5700.npy\n",
      "0   0.135248507596   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank118_nit5700.npy\n",
      "0   0.114057840827   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank99_nit5700.npy\n",
      "0   0.156031561545   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank107_nit5700.npy\n",
      "0   0.111252903697   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank26_nit5700.npy\n",
      "0   0.114809107097   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank31_nit5700.npy\n",
      "0   0.173925026882   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank116_nit5700.npy\n",
      "0   0.130201688368   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank94_nit5700.npy\n",
      "0   0.0925106099813   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank40_nit5700.npy\n",
      "0   0.111619236272   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank6_nit5700.npy\n",
      "0   0.1368146099   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank22_nit5700.npy\n",
      "0   0.114050431611   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank103_nit5700.npy\n",
      "0   0.111862471359   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank101_nit5700.npy\n",
      "0   0.138858650773   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank20_nit5700.npy\n",
      "0   0.110447067298   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank59_nit5700.npy\n",
      "0   0.105837469044   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank30_nit5700.npy\n",
      "0   0.114020087712   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank15_nit5700.npy\n",
      "0   0.104848575542   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank37_nit5700.npy\n",
      "0   0.105427957192   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank35_nit5700.npy\n",
      "0   0.178931506172   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank109_nit5700.npy\n",
      "0   0.0894168519636   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank113_nit5700.npy\n",
      "0   0.134301620612   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank58_nit5700.npy\n",
      "0   0.139089117857   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank27_nit5700.npy\n",
      "0   0.156949761821   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank84_nit5700.npy\n",
      "0   0.098232277886   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank10_nit5700.npy\n",
      "0   0.111252903697   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank25_nit5700.npy\n",
      "0   0.086778549247   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank105_nit5700.npy\n",
      "0   0.136027954632   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank102_nit5700.npy\n",
      "0   0.159572431516   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank74_nit5700.npy\n",
      "0   0.133627625232   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank36_nit5700.npy\n",
      "0   0.177349337367   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank83_nit5700.npy\n",
      "0   0.138100950064   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank56_nit5700.npy\n",
      "0   0.119536987456   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank90_nit5700.npy\n",
      "0   0.109888787212   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank79_nit5700.npy\n",
      "0   0.112726194899   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank81_nit5700.npy\n",
      "0   0.0979695457061   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank115_nit5700.npy\n",
      "0   0.096585297361   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank97_nit5700.npy\n",
      "0   0.101708174408   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank88_nit5700.npy\n",
      "0   0.148728664753   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank89_nit5700.npy\n",
      "0   0.105867098804   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank50_nit5700.npy\n",
      "0   0.139555644471   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank95_nit5700.npy\n",
      "0   0.098232277886   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank9_nit5700.npy\n",
      "0   0.115727959318   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank98_nit5700.npy\n",
      "0   0.10928790419   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank114_nit5700.npy\n",
      "0   0.191336515673   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank32_nit5700.npy\n",
      "0   0.121951991597   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank63_nit5700.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0.159572431516   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank73_nit5700.npy\n",
      "0   0.166725765077   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank87_nit5700.npy\n",
      "0   0.138858650773   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank19_nit5700.npy\n",
      "0   0.125685115343   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank85_nit5700.npy\n",
      "0   0.134215375969   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank42_nit5700.npy\n",
      "0   0.1368146099   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank23_nit5700.npy\n",
      "0   0.102437208324   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank67_nit5700.npy\n",
      "0   0.105427957192   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank34_nit5700.npy\n",
      "0   0.0818648807936   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank77_nit5700.npy\n",
      "0   0.160852992886   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank64_nit5700.npy\n",
      "0   0.189780007629   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank111_nit5700.npy\n",
      "0   0.125762983054   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank13_nit5700.npy\n",
      "0   0.142300218034   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank72_nit5700.npy\n",
      "0   0.197385640039   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank71_nit5700.npy\n",
      "0   0.124706237204   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank46_nit5700.npy\n",
      "0   0.147993166741   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank100_nit5700.npy\n",
      "0   0.199445165128   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank7_nit5700.npy\n",
      "0   0.145112314499   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank62_nit5700.npy\n",
      "0   0.116042502682   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank60_nit5700.npy\n",
      "0   0.106041362202   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank18_nit5700.npy\n",
      "0   0.112257078611   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank45_nit5700.npy\n",
      "0   0.0937367407815   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank43_nit5700.npy\n",
      "0   0.112077608833   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank53_nit5700.npy\n",
      "0   0.142243173669   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank110_nit5700.npy\n",
      "0   0.144362247429   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank48_nit5700.npy\n",
      "0   0.12000933157   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank57_nit5700.npy\n",
      "0   0.102437208324   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank68_nit5700.npy\n",
      "0   0.135248507596   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank117_nit5700.npy\n",
      "0   0.100357923143   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank82_nit5700.npy\n",
      "0   0.125482163352   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank21_nit5700.npy\n",
      "0   0.159572431516   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank75_nit5700.npy\n",
      "0   0.0909830071695   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank91_nit5700.npy\n",
      "0   0.152187037617   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank38_nit5700.npy\n",
      "0   0.0894168519636   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank112_nit5700.npy\n",
      "0   0.125762983054   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank14_nit5700.npy\n",
      "0   0.189649750074   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank44_nit5700.npy\n",
      "0   0.10231036189   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank76_nit5700.npy\n",
      "0   0.133222544271   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank61_nit5700.npy\n",
      "0   0.0925106099813   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank41_nit5700.npy\n",
      "0   0.116445045082   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank96_nit5700.npy\n",
      "0   0.0890080334898   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank3_nit5700.npy\n",
      "0   0.117380542302   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank119_nit5700.npy\n",
      "0   0.12917258911   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank29_nit5700.npy\n",
      "0   0.121616760786   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank65_nit5700.npy\n",
      "0   0.137654187052   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank55_nit5700.npy\n",
      "0   0.126274532704   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank17_nit5700.npy\n",
      "0   0.114976988708   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank70_nit5700.npy\n",
      "0   0.125470727274   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank33_nit5700.npy\n",
      "0   0.159615241152   /scratch/l/lfefebvr/noorir/model/Output/2019-04-12/1130634/scratch_/rank80_nit5700.npy\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "look at intermediate solutions\n",
    "\n",
    "@author: Rabiya Noori\n",
    "\"\"\"\n",
    "low= 500\n",
    "up = 10000\n",
    "job = JOB[1]\n",
    "\n",
    "__scale_arg1 = 0.5 * (low + up)\n",
    "__scale_arg2 = np.fabs(low - up)\n",
    "\n",
    "# exec(open(load_files[job]).read()) #loading variables into the environment\n",
    "# full_list = glob.glob(OUTPUT_PATH+\"*/\"+job+\"/scratch_/\"+\"rank*nit8500*\") #list of all results for a single job\n",
    "# if len(full_list) in NTASKS:\n",
    "#     low = 1\n",
    "#     for res in full_list:\n",
    "#         for i in range(1):\n",
    "#             temp_res = np.load(res)[i]\n",
    "#             res_scale = __scale_arg1 + (temp_res - 0.5) * __scale_arg2\n",
    "# #             print(res_scale)\n",
    "# #             print(temp_res)\n",
    "# #             print(np.shape(temp_res))\n",
    "#             temp_mse = hf.residuals_pli_corr(res_scale, wc_params, fs, nodes, targ_data_corr, \n",
    "#                                              targ_data_pli, w_mat, chunk, skip, wc_seed, evol_params['optim'], \n",
    "#                                              tract_mat, evol_params['heavi'], fmin, fmax)\n",
    "#             print(i, \" \", temp_mse, \" \", res)\n",
    "#             if temp_mse< low:\n",
    "#                 low = temp_mse\n",
    "#                 rank = res\n",
    "\n",
    "job = JOB[0]\n",
    "\n",
    "__scale_arg1 = 0.5 * (low + up)\n",
    "__scale_arg2 = np.fabs(low - up)\n",
    "\n",
    "exec(open(load_files[job]).read()) #loading variables into the environment\n",
    "full_list = glob.glob(OUTPUT_PATH+\"*/\"+job+\"/scratch_/\"+\"rank*nit5700*\") #list of all results for a single job\n",
    "if len(full_list) in NTASKS:\n",
    "    low = 1\n",
    "    for res in full_list:\n",
    "        for i in range(1):\n",
    "            temp_res = np.load(res)[i]\n",
    "            res_scale = __scale_arg1 + (temp_res - 0.5) * __scale_arg2\n",
    "            temp_mse = hf.residuals_pli_corr(res_scale, wc_params, fs, nodes, targ_data_corr, \n",
    "                                             targ_data_pli, w_mat, chunk, skip, wc_seed, evol_params['optim'], \n",
    "                                             tract_mat, evol_params['heavi'], fmin, fmax)\n",
    "            print(i, \" \", temp_mse, \" \", res)\n",
    "            if temp_mse< low:\n",
    "                low = temp_mse\n",
    "                rank = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_res = {} #dictionary of all the solution arrays\n",
    "temp_res = np.load(rank)[0]\n",
    "res_scale = __scale_arg1 + (temp_res - 0.5) * __scale_arg2\n",
    "all_res[job] = res_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mse = hf.residuals_pli_corr(all_res[job], wc_params, fs, nodes, targ_data_corr, \n",
    "                                 targ_data_pli, w_mat, chunk, skip, wc_seed, evol_params['optim'], \n",
    "                                             tract_mat, evol_params['heavi'], fmin, fmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1130634': array([ 4647.8348677 ,  5968.16239734,  2128.36338802,  1038.03087796,\n",
       "         5898.24643935,  1182.88084644,  1309.40867754,  8241.62713135,\n",
       "         3352.75961292,  2747.79877113,  4458.43251025,  1905.29525536,\n",
       "         6911.85924799,  7925.57241997,  7971.12457339,  4446.40509594,\n",
       "          908.99676989,  8894.95596046,  5146.89349287,  4258.24140972,\n",
       "         1925.0054833 ,  1253.91204332,  5026.14886732,   673.8858097 ,\n",
       "         7724.43105255,  5071.50200552,   588.68379891,  3901.77527316,\n",
       "          972.79700208,  8271.7013736 ,  7996.38080897,  7137.03527476,\n",
       "         6952.03280434,  3229.47037407,  8665.35436767,  8173.5294775 ,\n",
       "         7684.90920203,   656.34959041,  7333.0413815 ,  2107.56881231,\n",
       "         4055.51854025,  7077.0016805 ,  1851.11280415,  8731.41081731,\n",
       "         8327.53249822]),\n",
       " '1130638': array([ 4647.8348677 ,  5968.16239734,  2128.36338802,  1038.03087796,\n",
       "         5898.24643935,  1182.88084644,  1309.40867754,  8241.62713135,\n",
       "         3352.75961292,  2747.79877113,  4458.43251025,  1905.29525536,\n",
       "         6911.85924799,  7925.57241997,  7971.12457339,  4446.40509594,\n",
       "          908.99676989,  8894.95596046,  5146.89349287,  4258.24140972,\n",
       "         1925.0054833 ,  1253.91204332,  5026.14886732,   673.8858097 ,\n",
       "         7724.43105255,  5071.50200552,   588.68379891,  3901.77527316,\n",
       "          972.79700208,  8271.7013736 ,  7996.38080897,  7137.03527476,\n",
       "         6952.03280434,  3229.47037407,  8665.35436767,  8173.5294775 ,\n",
       "         7684.90920203,   656.34959041,  7333.0413815 ,  2107.56881231,\n",
       "         4055.51854025,  7077.0016805 ,  1851.11280415,  8731.41081731,\n",
       "         8327.53249822])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "2abec0de-20ee-4d4a-aa68-27bebcb71dcc"
    }
   },
   "outputs": [],
   "source": [
    "# Retreive the best solution - all_res is dict with arrays with the conduction \n",
    "# velocities vector that had the lowest MSE at the end of the diff evol algorithm\n",
    "\n",
    "all_res = {} #dictionary of all the solution arrays\n",
    "i=0\n",
    "job = JOB[0]\n",
    "exec(open(load_files[job]).read()) #loading variables into the environment\n",
    "full_list = glob.glob(OUTPUT_PATH+\"*/\"+job+\"/scratch_/\"+\"rank*nit5700*\") #list of all results for a single job\n",
    "if len(full_list) in NTASKS:\n",
    "    low = 1\n",
    "    for res in full_list:\n",
    "        temp_res = np.load(res)\n",
    "        print(np.shape(temp_res))\n",
    "        temp_mse = hf.residuals_pli_corr(temp_res, wc_params, fs, nodes, targ_data_corr, \n",
    "                                         targ_data_pli, w_mat, chunk, skip, wc_seed, evol_params['optim'], \n",
    "                                         tract_mat, evol_params['heavi'], fmin, fmax )\n",
    "\n",
    "        if temp_mse< low:\n",
    "            low = temp_mse\n",
    "            file = res\n",
    "    print(i,\" Job: \"+job+\", lowest MSE: \", low, file)\n",
    "    i = i+ 1\n",
    "\n",
    "else:\n",
    "    \n",
    "    print(\"Error\"+ job + \"len\" + str(len(full_list)))\n",
    "    \n",
    "job = JOB[1]\n",
    "full_list = glob.glob(OUTPUT_PATH+\"*/\"+job+\"/scratch_/\"+\"rank*nit8500*\") #list of all results for a single job\n",
    "if len(full_list) in NTASKS:\n",
    "    low = 1\n",
    "#     for res in full_list:\n",
    "#         start = res.index(\"_\")+1\n",
    "#         end = res.index(\".npy\")\n",
    "#         if float(res[start:end])< low:\n",
    "#             low = float(res[start:end])\n",
    "#     print(i,\" Job: \"+job+\", lowest MSE: \", low)\n",
    "#     i = i+ 1\n",
    "#     final_res_ = glob.glob(OUTPUT_PATH+\"*/\"+job+\"/\"+\"rank*\"+str(low)+\"*\")[0]\n",
    "#     all_res[job]= np.load(final_res_)\n",
    "else:\n",
    "    print(\"Error\", job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the result vectors for each run and calculating MSE for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_res[JOB[i]]/1000).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_mse = []\n",
    "all_res_true = {} #dictionary of all the target arrays\n",
    "import seaborn as sns\n",
    "for i in range(NUM_JOBS):\n",
    "    exec(open(load_files[JOB[i]]).read()) #loading variables into the environment\n",
    "    all_res_true[JOB[i]] = c_mat\n",
    "    if i == 1:\n",
    "        master_tract = tract_mat\n",
    "    \n",
    "# Calculate MSE between true and target for each\n",
    "    thing = np.triu(np.reciprocal(all_res_true[JOB[i]], where = all_res_true[JOB[i]] >0),1).ravel()\n",
    "    err = hf.mse(thing[thing != 0]/1000,all_res[JOB[i]]/1000)\n",
    "    all_mse.append(err)\n",
    "    print(JOB[i], \" true vs est: mse = \", err)\n",
    "    #if you want to white-out the diagonals:\n",
    "    #sns.heatmap(hf.p2matrix(thing[thing != 0],10)/1000, mask = hf.p2matrix(thing[thing != 0],10)/1000 ==0, \n",
    "    #            vmax = 10, vmin = 0.5, cmap = \"viridis\")\n",
    "    sns.heatmap(hf.p2matrix(thing[thing != 0],10)/1000, vmax = 10, vmin = 0.5, cmap = \"viridis\")\n",
    "    plt.xlabel(\"Node\", fontsize = 'large')\n",
    "    plt.ylabel(\"Node\", fontsize = 'large')\n",
    "    plt.show()\n",
    "    sns.heatmap(hf.p2matrix(all_res[JOB[i]],10)/1000, vmax = 10, vmin = 0.5, cmap = \"viridis\")\n",
    "    plt.xlabel(\"Node\")\n",
    "    plt.ylabel(\"Node\")\n",
    "    #plt.savefig(JOB[i]+\"est_cv.png\", facecolor = \"None\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a5c57588-181c-4686-8dfe-764df53298fc"
    }
   },
   "source": [
    "Plot of MEG time series of Target Data and Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(NUM_JOBS):\n",
    "    exec(open(load_files[JOB[i]]).read())\n",
    "    print(JOB[i])\n",
    "    \n",
    "    plt.figure(3, figsize=(15,6))\n",
    "    for sing_node in range(nodes):\n",
    "        plt.plot(ue_array[sing_node], '-k', linewidth=0.2)\n",
    "    avg = np.mean(ue_array, axis= 0 )\n",
    "    plt.plot(avg, '-k', linewidth = 0.8)\n",
    "    plt.xlabel(\"Time (ms)\", fontsize = \"xx-large\")\n",
    "    plt.ylabel(\"$u_e$\", fontsize = \"xx-large\")\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5cdc21b8-d5dc-4d10-ab16-c65602e99e13"
    }
   },
   "source": [
    "# STARTING ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting all histograms of all the conduction vel / weights estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(gr_means), np.mean(gr_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Estimates\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "gr_means = []\n",
    "gr_std = []\n",
    "for cv in range(8,12):\n",
    "\n",
    "    print(JOB[cv], \"cv estimate distribution\")\n",
    "    # the histogram of the data\n",
    "    n, bins, patches = plt.hist(all_res[JOB[cv]]/1000, density=True, facecolor='blue', alpha=0.5, range = (0.5,10))\n",
    "    \n",
    "    mu = np.average(all_res[JOB[cv]]/1000)\n",
    "    sigma = np.std(all_res[JOB[cv]]/1000)\n",
    "    \n",
    "    gr_means.append(mu)\n",
    "    gr_std.append(sigma)\n",
    "    # add a 'best fit' line\n",
    "    y = mlab.normpdf(bins, mu, sigma)\n",
    "    plt.plot(bins, y, 'r--')\n",
    "    plt.xlabel(\"Conduction Velocity (m/s)\", fontsize = 'x-large')\n",
    "    plt.xticks(fontsize = 13)\n",
    "    plt.yticks(fontsize = 13)\n",
    "    plt.ylabel('Normalized Count', fontsize = 'x-large')\n",
    "    plt.title(r'$\\mu={:.2f}$, $\\sigma={:.2f}$'.format(mu, sigma))\n",
    "\n",
    "    # Tweak spacing to prevent clipping of ylabel\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.show()\n",
    "    \n",
    "    print(JOB[cv], \"signal delay estimate distribution\")\n",
    "    trac = np.triu(master_tract,1).ravel()\n",
    "    trac= trac[trac > 0]\n",
    "    # the histogram of the data\n",
    "    n, bins, patches = plt.hist((trac/all_res[JOB[cv]])*1000, density=True, facecolor='blue', alpha=0.5, range = (0,100))\n",
    "    \n",
    "    mu = np.average((trac/all_res[JOB[cv]])*1000)\n",
    "    sigma = np.std((trac/all_res[JOB[cv]])*1000)\n",
    "    # add a 'best fit' line\n",
    "    y = mlab.normpdf(bins, mu, sigma)\n",
    "    plt.plot(bins, y, 'r--')\n",
    "    plt.xlabel(\"Signal Delays (ms)\", fontsize = 'x-large')\n",
    "    plt.xticks(fontsize = 13)\n",
    "    plt.yticks(fontsize = 13)\n",
    "    plt.ylabel('Normalized Count', fontsize = 'x-large')\n",
    "    plt.title(r'$\\mu={:.2f}$, $\\sigma={:.2f}$'.format(mu, sigma))\n",
    "\n",
    "    # Tweak spacing to prevent clipping of ylabel\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#True cv and signal delays\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "for cv in range(NUM_JOBS):    \n",
    "    # the histogram of the data\n",
    "    print(JOB[cv], \"cv true distribution\")\n",
    "    vec= np.reciprocal(all_res_true[JOB[cv]], where = all_res_true[JOB[0]] > 0 )/1000\n",
    "    vec = np.triu(vec,1).ravel()\n",
    "    vec = vec[vec != 0]\n",
    "    if vec.shape[0] ==45:\n",
    "        n, bins, patches = plt.hist(vec, density=True, facecolor='blue', alpha=0.5, range = (0.5,10))\n",
    "\n",
    "        mu = np.average(vec)\n",
    "        sigma = np.std(vec)\n",
    "        # add a 'best fit' line\n",
    "        y = mlab.normpdf(bins, mu, sigma)\n",
    "        plt.plot(bins, y, 'r--')\n",
    "        plt.xlabel(\"Conduction Velocity (m/s)\", fontsize = 'x-large')\n",
    "        plt.xticks(fontsize = 13)\n",
    "        plt.yticks(fontsize = 13)\n",
    "        plt.ylabel('Normalized Count', fontsize = 'x-large')\n",
    "        plt.title(r'$\\mu={:.2f}$, $\\sigma={:.2f}$'.format(mu, sigma))\n",
    "\n",
    "        # Tweak spacing to prevent clipping of ylabel\n",
    "        plt.subplots_adjust(left=0.15)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    # the histogram of the data\n",
    "    print(JOB[cv], \"signal delay true distribution\")\n",
    "    vec= np.reciprocal(all_res_true[JOB[cv]], where = all_res_true[JOB[0]] > 0 )/1000\n",
    "    vec = np.triu(vec,1).ravel()\n",
    "    vec = vec[vec != 0]\n",
    "    trac = np.triu(tract_mat,1).ravel()\n",
    "    trac= trac[trac > 0]\n",
    "    if vec.shape[0] ==45:\n",
    "        n, bins, patches = plt.hist(trac/vec, density=True, facecolor='blue', alpha=0.5, range = (0,100))\n",
    "\n",
    "        mu = np.average(trac/vec)\n",
    "        sigma = np.std(trac/vec)\n",
    "        # add a 'best fit' line\n",
    "        y = mlab.normpdf(bins, mu, sigma)\n",
    "        plt.plot(bins, y, 'r--')\n",
    "        plt.xlabel(\"Signal Delays (ms)\", fontsize = 'x-large')\n",
    "        plt.xticks(fontsize = 13)\n",
    "        plt.yticks(fontsize = 13)\n",
    "        plt.ylabel('Normalized Count', fontsize = 'x-large')\n",
    "        plt.title(r'$\\mu={:.2f}$, $\\sigma={:.2f}$'.format(mu, sigma))\n",
    "\n",
    "        # Tweak spacing to prevent clipping of ylabel\n",
    "        plt.subplots_adjust(left=0.15)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1844963f-f7a6-40a2-a212-7bbdf56ae6d9"
    }
   },
   "source": [
    "# Looking at solution matrices + time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1 : CORRELATION\n",
    "for i in range(0,3):\n",
    "    exec(open(load_files[JOB[i]]).read()) #loading variables into the environment\n",
    "    print(JOB[i])\n",
    "    cmat_old_, ue_array_, res_, vmax_ , vmin_ = hf.residuals_cw_corr(all_res[JOB[i]], wc_params, nodes, targ_data, w_mat,\n",
    "                                            skip, wc_seed, evol_params['optim'], tract_mat, \n",
    "                                            heavyside= evol_params['heavi'],plot =\"cw\")\n",
    "    \n",
    "    #plot the correlation matrix\n",
    "    import seaborn as sns\n",
    "    skip = 200\n",
    "    exp_data = hf.plot_cor_mat(ue_array_, nodes, skip)\n",
    "    np.fill_diagonal(exp_data, 0)\n",
    "    plt.figure()\n",
    "    sns.heatmap(exp_data, cmap =\"viridis\", vmax = 1, vmin =-1)\n",
    "    plt.xlabel(\"Node\", fontsize = 'large')\n",
    "    plt.ylabel(\"Node\", fontsize = 'large')\n",
    "    plt.savefig(JOB[i]+\"corr.png\", facecolor = \"None\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #plot the true correlation matrix\n",
    "    import seaborn as sns\n",
    "    skip = 200\n",
    "    plt.figure()\n",
    "    sns.heatmap(targ_data, cmap =\"viridis\", vmax = 1, vmin =-1)\n",
    "    plt.xlabel(\"Node\", fontsize = 'large')\n",
    "    plt.ylabel(\"Node\", fontsize = 'large')\n",
    "    plt.savefig(JOB[i]+\"corr_true.png\", facecolor = \"None\")\n",
    "    plt.show()\n",
    "    print(\"MSE\", res_)\n",
    "\n",
    "    #experimental time series\n",
    "    plt.figure(3, figsize=(15,6))\n",
    "    for sing_node in range(nodes):\n",
    "        plt.plot(ue_array_[sing_node], '-k', linewidth=0.2)\n",
    "    avg = np.mean(ue_array_, axis= 0 )\n",
    "    plt.plot(avg, '-k', linewidth = 0.8)\n",
    "    plt.xlabel(\"Time (ms)\", fontsize = \"xx-large\")\n",
    "    plt.ylabel(\"$u_e$\", fontsize = \"xx-large\")\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    plt.savefig(JOB[i]+\"ts.png\", facecolor = \"None\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2 : PLI\n",
    "for i in range(3,6):\n",
    "    exec(open(load_files[JOB[i]]).read()) #loading variables into the environment\n",
    "    print(JOB[i])\n",
    "    cmat_old_, ue_array_, res_, exp_pli = hf.residuals_pli(all_res[JOB[i]], wc_params, fs, nodes, targ_data, w_mat, chunk,\n",
    "                                            skip, wc_seed, evol_params['optim'], tract_mat, \n",
    "                                            evol_params['heavi'], fmin, fmax, plot = True)\n",
    "    \n",
    "    #plot the pli matrix\n",
    "    import seaborn as sns\n",
    "    skip = 200\n",
    "    exp_data = exp_pli\n",
    "    for row in range(1,nodes):\n",
    "        for col in range(0, row):\n",
    "            exp_data[col,row] = exp_data[row,col]\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.heatmap(exp_data, cmap =\"viridis\", vmax = 1, vmin =0)\n",
    "    plt.xlabel(\"Node\", fontsize = 'large')\n",
    "    plt.ylabel(\"Node\", fontsize = 'large')\n",
    "    plt.savefig(JOB[i]+\"pli.png\", facecolor = \"None\")\n",
    "    plt.show()\n",
    "    print(exp_data)\n",
    "    \n",
    "    #plot the true pli matrix\n",
    "    import seaborn as sns\n",
    "    skip = 200\n",
    "    \n",
    "    exp_data = targ_data\n",
    "    for row in range(1,nodes):\n",
    "        for col in range(0, row):\n",
    "            exp_data[col,row] = exp_data[row,col]\n",
    "\n",
    "            \n",
    "    plt.figure()\n",
    "    sns.heatmap(exp_data, cmap =\"viridis\", vmax = 1, vmin =0)\n",
    "    plt.xlabel(\"Node\", fontsize = 'large')\n",
    "    plt.ylabel(\"Node\", fontsize = 'large')\n",
    "    plt.savefig(JOB[i]+\"pli_true.png\", facecolor = \"None\")\n",
    "    plt.show()\n",
    "    print(\"MSE\", res_)\n",
    "\n",
    "\n",
    "    #experimental time series\n",
    "    plt.figure(3, figsize=(15,6))\n",
    "    for sing_node in range(nodes):\n",
    "        plt.plot(ue_array_[sing_node], '-k', linewidth=0.2)\n",
    "    avg = np.mean(ue_array_, axis= 0 )\n",
    "    plt.plot(avg, '-k', linewidth = 0.8)\n",
    "    plt.xlabel(\"Time (ms)\", fontsize = \"xx-large\")\n",
    "    plt.ylabel(\"$u_e$\", fontsize = \"xx-large\")\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    plt.savefig(JOB[i]+\"ts.png\", facecolor = \"None\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3 : CORRELATION + PLI\n",
    "for i in range(4,8):\n",
    "    exec(open(load_files[JOB[i]]).read()) #loading variables into the environment\n",
    "    print(JOB[i])\n",
    "    cmat_old_, ue_array_, res_, exp_data_pli_, exp_data_corr_ = hf.residuals_pli_corr(all_res[JOB[i]], wc_params, fs, nodes,\n",
    "                                                                    targ_data_corr, targ_data_pli, w_mat, chunk, skip, wc_seed,\n",
    "                                                                     evol_params['optim'], tract_mat,\n",
    "                                                                     evol_params['heavi'], \n",
    "                                                                     fmin, fmax, plot = True)\n",
    "    \n",
    "    #plot the correlation matrix\n",
    "    import seaborn as sns\n",
    "    skip = 200\n",
    "    exp_data = hf.plot_cor_mat(ue_array_, nodes, skip)\n",
    "    np.fill_diagonal(exp_data_corr_, 0)\n",
    "    plt.figure()\n",
    "    sns.heatmap(exp_data_corr_, cmap =\"viridis\", vmax = 1, vmin =-1)\n",
    "    plt.xlabel(\"Node\", fontsize = 'large')\n",
    "    plt.ylabel(\"Node\", fontsize = 'large')\n",
    "    plt.savefig(JOB[i]+\"corr.png\", facecolor = \"None\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    #plot the pli matrix\n",
    "    import seaborn as sns\n",
    "    skip = 200\n",
    "    \n",
    "    exp_data = exp_data_pli_\n",
    "    for row in range(1,nodes):\n",
    "        for col in range(0, row):\n",
    "            exp_data[col,row] = exp_data[row,col]\n",
    "            \n",
    "    plt.figure()\n",
    "    sns.heatmap(exp_data, cmap =\"viridis\", vmax = 1, vmin =0)\n",
    "    plt.xlabel(\"Node\", fontsize = 'large')\n",
    "    plt.ylabel(\"Node\", fontsize = 'large')\n",
    "    plt.savefig(JOB[i]+\"pli.png\", facecolor = \"None\")\n",
    "\n",
    "    plt.show()\n",
    "    print(\"MSE\", res_)\n",
    "\n",
    "    #experimental time series\n",
    "    plt.figure(3, figsize=(15,6))\n",
    "    for sing_node in range(nodes):\n",
    "        plt.plot(ue_array_[sing_node], '-k', linewidth=0.2)\n",
    "    avg = np.mean(ue_array, axis= 0 )\n",
    "    plt.plot(avg, '-k', linewidth = 0.8)\n",
    "    plt.xlabel(\"Time (ms)\", fontsize = \"xx-large\")\n",
    "    plt.ylabel(\"$u_e$\", fontsize = \"xx-large\")\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    plt.savefig(JOB[i]+\"ts.png\", facecolor = \"None\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# plt.figure(figsize=(15.0,15.0))\n",
    "import matplotlib.mlab as mlab\n",
    "import scipy.stats as ss\n",
    "\n",
    "pl_rows = 3 \n",
    "pl_col = 3 \n",
    "range_st = 500 \n",
    "range_en= 10000\n",
    "for i in range(3,6): \n",
    "    #plt.subplot(pl_rows, pl_col, i+1)\n",
    "\n",
    "\n",
    "    print(i+1, \"JOB #: \", JOB[i], \"min: {} max: {} avg: {}\".format(np.min(all_res[JOB[i]]), \n",
    "                                                                   np.max(all_res[JOB[i]]), np.average(all_res[JOB[i]])))\n",
    "#     bins=np.arange(range_st, range_en, 100)\n",
    "    \n",
    "    true = np.triu(np.reciprocal(all_res_true[JOB[i]]),1).ravel()\n",
    "    est = all_res[JOB[i]]\n",
    "    \n",
    "    mu_true = np.average(true[true != 0])\n",
    "    sigma_true = np.std(true[true != 0])\n",
    "    \n",
    "    mu_est = np.average(est)\n",
    "    sigma_est = np.std(est)\n",
    "    \n",
    "    plt.style.use('seaborn-deep')\n",
    "#     n, bins, patches  = plt.hist([true, est], range = (range_st,range_en), label=['True', 'Estimate'])\n",
    "#     y_true = ss.norm.pdf(bins[0], mu_true, sigma_true)\n",
    "#     plt.plot(bins, y_true, 'b--')\n",
    "    \n",
    "#     y_est = mlab.normpdf(bins[1], mu_est, sigma_est)\n",
    "#     plt.plot(bins, y_est, 'g--')\n",
    "\n",
    "    n, bins, patches= plt.hist(true[true != 0], range = (range_st,range_en), label='True', alpha = 0.6, normed = 1)\n",
    "    y_true = ss.norm.pdf(bins, mu_true, sigma_true)\n",
    "    print(mu_true, mu_est, \"HERE\")\n",
    "    \n",
    "    plt.plot(bins, y_true, 'b--')\n",
    "    \n",
    "    \n",
    "#     plt.hist(est, range = (range_st,range_en), label='Estimate', alpha = 0.5, bins = bins)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    #plt.hist([true, est], range = (500, 10000), facecolor ='g')\n",
    "#     mu = np.average(all_res[JOB[i]])\n",
    "#     plt.text(60, .025, r'$\\mu=\\$')\n",
    "    \n",
    "    #plt.hist(np.reciprocal(all_res_true[JOB[i]]), range = (500, 10000), facecolor = 'b')\n",
    "    #plt.text(np.average(np.reciprocal(all_res_true[JOB[i]]), r'$\\mu=100$')\n",
    "    \n",
    "    plt.xlabel(\"Conduction Velocity\", fontsize = 'x-large')\n",
    "    plt.xticks(fontsize = 13)\n",
    "    plt.show()\n",
    "    #row major counting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true[true!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing  = np.triu(np.reciprocal(all_res_true[JOB[0]]),1).ravel()\n",
    "thing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.p2matrix(all_res[JOB[i]], 10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left  = 0.125  # the left side of the subplots of the figure\n",
    "right = 0.9    # the right side of the subplots of the figure\n",
    "bottom = 0.1   # the bottom of the subplots of the figure\n",
    "\n",
    "top = 0.9      # the top of the subplots of the figure\n",
    "wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
    "hspace = 0.2   # the amount of height reserved for white space between subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ALL THE RESULTS AT ONCE\n",
    "\n",
    "for i in range(1, 4):\n",
    "    exec(open(load_files[JOB[i]]).read()) #loading variables into the environment\n",
    "    print(JOB[i])\n",
    "    final_res = hf.residuals_cw_corr(all_res[JOB[i]], wc_params, nodes, targ_data, MAT,\n",
    "                                            skip, wc_seed, evol_params['optim'], tract_mat, heavyside= evol_params['heavi'],\n",
    "                                     plot =\"cw\", vmax_= 10, vmin_=0.5)\n",
    "\n",
    "\"\"\"  \n",
    "    ind = 0\n",
    "    mat = np.ones((nodes, nodes))\n",
    "    c = np.reciprocal(all_res[JOB[i]])\n",
    "    for row in range(0,nodes):\n",
    "        \n",
    "        for col in range(row+1, nodes):\n",
    "            mat[row,col] =c[ind]\n",
    "            mat[col,row] = c[ind]\n",
    "            ind += 1\n",
    "    np.fill_diagonal(mat,0)\n",
    "    #mat[0:5,5:10] =0\n",
    "    #mat[5:10,0:5] =0\n",
    "    plt.figure()\n",
    "    plt.hist(mat, range=(3000,7000))\n",
    "    plt.show()\n",
    "    print(\"JOB #: {}, max: {} min: {}\".format(JOB[i],np.max(c), np.min(c)))\n",
    "    plt.figure()\n",
    "    sns.heatmap(mat, cmap = \"viridis\", vmax =7000, vmin = 3000)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ALL THE RESULTS AT ONCE\n",
    "\n",
    "for i in range(4, NUM_JOBS):\n",
    "    exec(open(load_files[JOB[i]]).read()) #loading variables into the environment\n",
    "    print(JOB[i])\n",
    "    final_res = hf.residuals_cw_corr(all_res[JOB[i]], wc_params, nodes, targ_data, MAT,\n",
    "                                            skip, wc_seed, evol_params['optim'], tract_mat, heavyside= evol_params['heavi'],\n",
    "                                     plot =\"cw\", vmax_= 5, vmin_=0.5)\n",
    "\n",
    "\"\"\"  \n",
    "    ind = 0\n",
    "    mat = np.ones((nodes, nodes))\n",
    "    c = np.reciprocal(all_res[JOB[i]])\n",
    "    for row in range(0,nodes):\n",
    "        \n",
    "        for col in range(row+1, nodes):\n",
    "            mat[row,col] =c[ind]\n",
    "            mat[col,row] = c[ind]\n",
    "            ind += 1\n",
    "    np.fill_diagonal(mat,0)\n",
    "    #mat[0:5,5:10] =0\n",
    "    #mat[5:10,0:5] =0\n",
    "    plt.figure()\n",
    "    plt.hist(mat, range=(3000,7000))\n",
    "    plt.show()\n",
    "    print(\"JOB #: {}, max: {} min: {}\".format(JOB[i],np.max(c), np.min(c)))\n",
    "    plt.figure()\n",
    "    sns.heatmap(mat, cmap = \"viridis\", vmax =7000, vmin = 3000)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(tract_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(targ_data, cmap=\"viridis\", vmin = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_p = np.array(hf.matrix2p(tract_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res[JOB[i]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = tract_p==0\n",
    "c = all_res[JOB[i]][where]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(all_res[JOB[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
